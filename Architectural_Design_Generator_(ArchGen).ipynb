{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "sourceId": 8079562,
          "sourceType": "datasetVersion",
          "datasetId": 4768545
        }
      ],
      "dockerImageVersionId": 30684,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Architectural Design Generator (ArchGen)",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danusyasundaravel/Deepfake-detection/blob/main/Architectural_Design_Generator_(ArchGen).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "adilmohammed_floor_plan_images_and_their_details_path = kagglehub.dataset_download('adilmohammed/floor-plan-images-and-their-details')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "xJDNb1aIfDsx"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the folder containing the images\n",
        "images_folder = \"/kaggle/input/floor-plan-images-and-their-details/images/images\"\n",
        "\n",
        "# Path to the CSV file containing details\n",
        "dataset_path = \"/kaggle/input/floor-plan-images-and-their-details/house_plans_details.csv\"\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Get the list of image filenames\n",
        "images = os.listdir(images_folder)\n",
        "\n",
        "# Display the first four images\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(3):\n",
        "    # Read the image\n",
        "    image_path = os.path.join(images_folder, images[i])\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convert BGR image to RGB for displaying with matplotlib\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display the image\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Image {i+1}\")\n",
        "\n",
        "plt.show()\n",
        "data.head(3)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-12T13:56:12.953277Z",
          "iopub.execute_input": "2024-04-12T13:56:12.954082Z",
          "iopub.status.idle": "2024-04-12T13:56:18.486988Z",
          "shell.execute_reply.started": "2024-04-12T13:56:12.954051Z",
          "shell.execute_reply": "2024-04-12T13:56:18.486212Z"
        },
        "trusted": true,
        "id": "uKOK8E7lfDsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMissing values:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Convert data types of \"Square Feet\", \"Beds\", and \"Garages\" columns to integer\n",
        "data[\"Square Feet\"] = data[\"Square Feet\"].astype(int)\n",
        "data[\"Beds\"] = data[\"Beds\"].astype(int)\n",
        "data[\"Garages\"] = data[\"Garages\"].astype(int)\n",
        "\n",
        "# Check the data types after conversion\n",
        "print(\"Data types after conversion:\")\n",
        "print(data.dtypes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-12T13:56:18.488569Z",
          "iopub.execute_input": "2024-04-12T13:56:18.489063Z",
          "iopub.status.idle": "2024-04-12T13:56:18.633483Z",
          "shell.execute_reply.started": "2024-04-12T13:56:18.489031Z",
          "shell.execute_reply": "2024-04-12T13:56:18.632492Z"
        },
        "trusted": true,
        "id": "DdJIScMmfDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "data1 = data.drop('Image Path', axis=1)\n",
        "sns.heatmap(data1.corr(), annot = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-12T13:56:18.634811Z",
          "iopub.execute_input": "2024-04-12T13:56:18.63521Z",
          "iopub.status.idle": "2024-04-12T13:56:20.414024Z",
          "shell.execute_reply.started": "2024-04-12T13:56:18.635166Z",
          "shell.execute_reply": "2024-04-12T13:56:20.41332Z"
        },
        "trusted": true,
        "id": "dlzTw0TafDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install plotly"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-12T13:56:20.414937Z",
          "iopub.execute_input": "2024-04-12T13:56:20.415288Z",
          "iopub.status.idle": "2024-04-12T13:56:34.798828Z",
          "shell.execute_reply.started": "2024-04-12T13:56:20.415253Z",
          "shell.execute_reply": "2024-04-12T13:56:34.797734Z"
        },
        "trusted": true,
        "id": "sRlrpq1vfDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Interactive Scatter Plot: Square Feet vs. Beds\n",
        "scatter_fig = px.scatter(data, x='Square Feet', y='Beds', title='Square Feet vs. Beds')\n",
        "\n",
        "# Box Plot: Distribution of Square Feet by Number of Bedrooms\n",
        "box_fig = px.box(data, x='Beds', y='Square Feet', title='Distribution of Square Feet by Number of Bedrooms')\n",
        "\n",
        "\n",
        "# Faceted Plot: Square Feet vs. Beds (Faceted by Number of Bathrooms)\n",
        "faceted_fig = px.scatter(data, x='Beds', y='Square Feet', color='Baths', facet_col='Baths',\n",
        "                         labels={'Beds': 'Number of Bedrooms', 'Square Feet': 'Square Feet', 'Baths': 'Number of Bathrooms'},\n",
        "                         title='Square Feet vs. Beds (Faceted by Number of Bathrooms)')\n",
        "# Violin Plot: Distribution of Square Feet\n",
        "violin_fig = px.violin(data, y='Square Feet', title='Distribution of Square Feet')\n",
        "\n",
        "# Display the plots\n",
        "scatter_fig.show()\n",
        "box_fig.show()\n",
        "violin_fig.show()\n",
        "faceted_fig.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-12T13:56:34.801325Z",
          "iopub.execute_input": "2024-04-12T13:56:34.801691Z",
          "iopub.status.idle": "2024-04-12T13:56:35.648155Z",
          "shell.execute_reply.started": "2024-04-12T13:56:34.801662Z",
          "shell.execute_reply": "2024-04-12T13:56:35.647389Z"
        },
        "trusted": true,
        "id": "ldQHl9xifDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the target image size\n",
        "target_size = (64, 64)  # Example target size\n",
        "\n",
        "# Initialize an empty list to store preprocessed images\n",
        "preprocessed_images = []\n",
        "\n",
        "# Loop through each image file path\n",
        "for image_path in images:\n",
        "    # Read the image\n",
        "    image = cv2.imread(os.path.join(images_folder, image_path))\n",
        "\n",
        "    # Resize the image\n",
        "    resized_image = cv2.resize(image, target_size)\n",
        "\n",
        "    # Normalize pixel values to range [0, 1]\n",
        "    normalized_image = resized_image / 255.0\n",
        "\n",
        "    # Convert the image to NumPy array and append to the list\n",
        "    preprocessed_images.append(normalized_image)\n",
        "\n",
        "# Convert the list of images to NumPy array\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "\n",
        "# Display the shape of the preprocessed images array\n",
        "print(\"Shape of preprocessed images array:\", preprocessed_images.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-12T13:56:35.649127Z",
          "iopub.execute_input": "2024-04-12T13:56:35.649415Z",
          "iopub.status.idle": "2024-04-12T13:57:45.020166Z",
          "shell.execute_reply.started": "2024-04-12T13:56:35.649386Z",
          "shell.execute_reply": "2024-04-12T13:57:45.019466Z"
        },
        "trusted": true,
        "id": "0BOu-I_7fDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install optree"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-12T13:57:45.02113Z",
          "iopub.execute_input": "2024-04-12T13:57:45.021397Z",
          "iopub.status.idle": "2024-04-12T13:57:48.778417Z",
          "shell.execute_reply.started": "2024-04-12T13:57:45.02137Z",
          "shell.execute_reply": "2024-04-12T13:57:48.77731Z"
        },
        "trusted": true,
        "id": "XnePIP-IfDsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow keras"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-12T13:57:48.779719Z",
          "iopub.execute_input": "2024-04-12T13:57:48.780003Z",
          "iopub.status.idle": "2024-04-12T13:58:56.628017Z",
          "shell.execute_reply.started": "2024-04-12T13:57:48.779973Z",
          "shell.execute_reply": "2024-04-12T13:58:56.627088Z"
        },
        "trusted": true,
        "id": "zTmpmBVEfDsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Reshape, Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, Input, Concatenate\n",
        "from tensorflow.keras.layers import Flatten, LeakyReLU, Input\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the dimensions of the random noise vector\n",
        "latent_dim = 100\n",
        "\n",
        "# Define the generator network\n",
        "def build_generator():\n",
        "    input_details = Input(shape=(4,))\n",
        "    x = Dense(256)(input_details)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dense(128)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    output = Dense(64 * 64 * 3, activation='tanh')(x)\n",
        "    output = Reshape((64, 64, 3))(output)\n",
        "    model = Model(input_details, output)\n",
        "    return model\n",
        "\n",
        "# Define the discriminator network\n",
        "def build_discriminator():\n",
        "    input_image = Input(shape=(64, 64, 3))\n",
        "    x = Conv2D(64, (3,3), strides=(2,2), padding='same')(input_image)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Conv2D(128, (3,3), strides=(2,2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Conv2D(256, (3,3), strides=(2,2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Flatten()(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(input_image, output)\n",
        "    return model\n",
        "\n",
        "# Define the combined GAN model\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    input_details = Input(shape=(4,))\n",
        "    generated_image = generator(input_details)\n",
        "    validity = discriminator(generated_image)\n",
        "    model = Model(input_details, validity)\n",
        "    return model\n",
        "\n",
        "# Build and compile the discriminator\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
        "\n",
        "# Build the generator\n",
        "generator = build_generator()\n",
        "\n",
        "# Build and compile the combined GAN model\n",
        "gan = build_gan(generator, discriminator)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
        "\n",
        "# Training loop\n",
        "# Training loop\n",
        "# Training loop\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch_index in range(len(preprocessed_images) // batch_size):\n",
        "        # Sample random noise vectors\n",
        "        noise = np.random.randn(batch_size, 4)  # Ensure input shape matches generator input\n",
        "\n",
        "        # Generate fake images\n",
        "        generated_images = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator\n",
        "        real_images = preprocessed_images[batch_index * batch_size: (batch_index + 1) * batch_size]\n",
        "        combined_images = np.concatenate([real_images, generated_images])\n",
        "        labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
        "        labels += 0.05 * np.random.random(labels.shape)\n",
        "        discriminator_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "        # Train the generator\n",
        "        noise = np.random.randn(batch_size, 4)  # Ensure input shape matches generator input\n",
        "        misleading_labels = np.ones((batch_size, 1))\n",
        "        generator_loss = gan.train_on_batch(noise, misleading_labels)\n",
        "\n",
        "    # Print progress\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}')\n",
        "\n",
        "# Function to generate images based on input details\n",
        "def generate_images(square_feet, beds, baths, garages):\n",
        "    input_details = np.array([[square_feet, beds, baths, garages]])\n",
        "    generated_image = generator.predict(input_details)\n",
        "    generated_image = np.squeeze(generated_image, axis=0)  # Remove batch dimension\n",
        "    generated_image = (generated_image * 0.5) + 0.5  # Rescale pixel values to [0, 1]\n",
        "    return generated_image\n",
        "\n",
        "# Example usage\n",
        "new_image = generate_images(2500, 3, 2, 2)  # Provide input details\n",
        "plt.imshow(new_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-12T14:02:18.605796Z",
          "iopub.execute_input": "2024-04-12T14:02:18.606144Z"
        },
        "trusted": true,
        "id": "eh-U_91sfDsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m41kpIH_fDsz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}