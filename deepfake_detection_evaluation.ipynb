{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kq2IinuYVdk",
        "outputId": "e9a6e0e2-0abc-42cf-d53b-519b14df7879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "cnn_model = load_model('/content/model.h5')\n",
        "cnn_3d_model = load_model('/content/3d_cnn_deepfake_detection.h5')\n",
        "efficientnet_model = load_model('/content/detection.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wDUNrwxjY8LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "test_dir = '/content/drive/MyDrive/crop_face/faces'\n",
        "real_test_dir = os.path.join(test_dir, 'real_video')\n",
        "fake_test_dir = os.path.join(test_dir, 'fake_video')\n",
        "\n",
        "def load_test_images(image_dir, target_size=(128, 128)):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    for label, folder_name in [(0, 'real_video'), (1, 'fake_video')]:\n",
        "        folder_path = os.path.join(image_dir, folder_name)\n",
        "        # Loop through each subdirectory\n",
        "        for subdir in os.listdir(folder_path):\n",
        "            subdir_path = os.path.join(folder_path, subdir)\n",
        "            if os.path.isdir(subdir_path):\n",
        "                for img_file in os.listdir(subdir_path):\n",
        "                    if img_file.endswith('.jpg'):\n",
        "                        img_path = os.path.join(subdir_path, img_file)\n",
        "                        image_paths.append(img_path)\n",
        "                        labels.append(label)\n",
        "\n",
        "    # Load images and resize\n",
        "    images = [cv2.resize(cv2.imread(path), target_size).astype('float32') / 255.0 for path in image_paths]\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load test images\n",
        "X_test, y_test = load_test_images(test_dir)\n"
      ],
      "metadata": {
        "id": "esaBmbx7afRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the CNN model on the test set\n",
        "cnn_loss, cnn_acc = cnn_model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"CNN Model - Test Loss: {cnn_loss}, Test Accuracy: {cnn_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxVy4HtNa2ua",
        "outputId": "7881c701-6498-4893-ea04-cc266f8c31af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9614 - loss: 0.0967\n",
            "CNN Model - Test Loss: 0.08062057942152023, Test Accuracy: 0.9668921232223511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def load_test_sequences(base_dir, sequence_length, target_size=(64, 64)):\n",
        "    face_sequences = []\n",
        "    labels = []\n",
        "\n",
        "\n",
        "    for video_type, label_value in [('real_video', 0), ('fake_video', 1)]:\n",
        "        video_dir = os.path.join(base_dir, video_type)\n",
        "        if not os.path.exists(video_dir):\n",
        "            continue\n",
        "\n",
        "\n",
        "        for subdir in os.listdir(video_dir):\n",
        "            subdir_path = os.path.join(video_dir, subdir)\n",
        "            if not os.path.isdir(subdir_path):\n",
        "                continue\n",
        "\n",
        "\n",
        "            face_files = sorted([f for f in os.listdir(subdir_path) if f.endswith('.jpg')])\n",
        "\n",
        "\n",
        "            num_sequences = len(face_files) - sequence_length + 1\n",
        "            # Ensure that the number of sequences matches the number of labels\n",
        "            # by taking only non-overlapping sequences\n",
        "            for i in range(0, num_sequences, sequence_length):\n",
        "                sequence = face_files[i:i + sequence_length]\n",
        "\n",
        "                # Check if the sequence has enough frames\n",
        "                if len(sequence) == sequence_length:\n",
        "                    face_sequences.append([os.path.join(subdir_path, frame) for frame in sequence])\n",
        "                    labels.append(label_value)\n",
        "\n",
        "\n",
        "    X_test1 = []\n",
        "    for sequence in face_sequences:\n",
        "        frames = [cv2.resize(cv2.imread(frame), target_size).astype('float32') / 255.0 for frame in sequence]\n",
        "        X_test1.append(np.stack(frames))\n",
        "\n",
        "    return np.array(X_test1), np.array(labels) # Return X_test1 instead of X_test\n",
        "\n",
        "# Set test data directory and sequence length\n",
        "sequence_length = 10\n",
        "X_test1, y_test1 = load_test_sequences(test_dir, sequence_length)"
      ],
      "metadata": {
        "id": "RKt5VXHchYJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSCJvQJHhd1G",
        "outputId": "fd386acc-5025-4ef4-c7b9-8420fca8b959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(268, 10, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSzlCYZEhgaB",
        "outputId": "ad9538c5-1ef7-460b-afce-e4a9bfbfe392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(268,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the 3D CNN model on the test set\n",
        "cnn_3d_loss, cnn_3d_acc = cnn_3d_model.evaluate(X_test1, y_test1, verbose=1)\n",
        "print(f\"3D CNN Model - Test Loss: {cnn_3d_loss}, Test Accuracy: {cnn_3d_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvEXvA9ca7TB",
        "outputId": "ec1238a1-0a5b-4f91-c50c-bbf2f87405ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.5805 - loss: 0.6970\n",
            "3D CNN Model - Test Loss: 0.7007034420967102, Test Accuracy: 0.60447758436203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the EfficientNet model on the test set\n",
        "efficientnet_loss, efficientnet_acc = efficientnet_model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"EfficientNet Model - Test Loss: {efficientnet_loss}, Test Accuracy: {efficientnet_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2HSSadra9Lk",
        "outputId": "1fbdf2da-73e3-428c-cfaa-8a638216c150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 69ms/step - accuracy: 0.0924 - loss: 0.6961\n",
            "EfficientNet Model - Test Loss: 0.6939706802368164, Test Accuracy: 0.3851904571056366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Get predictions\n",
        "y_pred = np.round(cnn_model.predict(X_test)).astype(int)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk6HVOnPhsAW",
        "outputId": "001f8063-1e3a-4d7a-a037-dc82483fb122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97      1727\n",
            "           1       0.94      0.98      0.96      1082\n",
            "\n",
            "    accuracy                           0.97      2809\n",
            "   macro avg       0.96      0.97      0.97      2809\n",
            "weighted avg       0.97      0.97      0.97      2809\n",
            "\n",
            "[[1658   69]\n",
            " [  24 1058]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the pre-trained 3D CNN model\n",
        "model = load_model('3d_cnn_deepfake_detection.h5')\n",
        "\n",
        "# Define a function to extract frames from the video\n",
        "def extract_frames_from_video(video_path, target_size=(64, 64)):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Resize the frame\n",
        "        resized_frame = cv2.resize(frame, target_size)\n",
        "        normalized_frame = resized_frame.astype('float32') / 255.0  # Normalize to [0,1]\n",
        "\n",
        "        frames.append(normalized_frame)\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "# Define a function to create sequences of frames\n",
        "def create_frame_sequences(frames, sequence_length):\n",
        "    sequences = []\n",
        "    for i in range(0, len(frames) - sequence_length + 1):\n",
        "        sequence = frames[i:i + sequence_length]\n",
        "        sequences.append(sequence)\n",
        "    return np.array(sequences)\n",
        "\n",
        "# Path to the video file\n",
        "video_path = '/content/00010.mp4'\n",
        "\n",
        "# Extract frames from the video\n",
        "frames = extract_frames_from_video(video_path)\n",
        "\n",
        "# Check if the number of frames is less than the required sequence length\n",
        "sequence_length = 10  # This should match what the 3D CNN model was trained on\n",
        "if len(frames) < sequence_length:\n",
        "    print(f\"Video is too short! Needs at least {sequence_length} frames.\")\n",
        "else:\n",
        "    # Create sequences from the frames\n",
        "    frame_sequences = create_frame_sequences(frames, sequence_length)\n",
        "\n",
        "    # Predict using the 3D CNN model\n",
        "    predictions = model.predict(frame_sequences)\n",
        "\n",
        "    # Average the predictions across all sequences\n",
        "    avg_prediction = np.mean(predictions)\n",
        "\n",
        "    # Output the result\n",
        "    if avg_prediction > 0.5:\n",
        "        print(f\"Prediction: Deepfake (Confidence: {avg_prediction * 100:.2f}%)\")\n",
        "    else:\n",
        "        print(f\"Prediction: Real (Confidence: {(1 - avg_prediction) * 100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5N1hKh8h7Jz",
        "outputId": "07baadee-2052-4f1b-c7b2-3a73d545ddf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step\n",
            "Prediction: Deepfake (Confidence: 100.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the video file\n",
        "video_path = '/content/00096.mp4'\n",
        "\n",
        "# Extract frames from the video\n",
        "frames = extract_frames_from_video(video_path)\n",
        "\n",
        "# Check if the number of frames is less than the required sequence length\n",
        "sequence_length = 10  # This should match what the 3D CNN model was trained on\n",
        "if len(frames) < sequence_length:\n",
        "    print(f\"Video is too short! Needs at least {sequence_length} frames.\")\n",
        "else:\n",
        "    # Create sequences from the frames\n",
        "    frame_sequences = create_frame_sequences(frames, sequence_length)\n",
        "\n",
        "    # Predict using the 3D CNN model\n",
        "    predictions = model.predict(frame_sequences)\n",
        "\n",
        "    # Average the predictions across all sequences\n",
        "    avg_prediction = np.mean(predictions)\n",
        "\n",
        "    # Output the result\n",
        "    if avg_prediction > 0.5:\n",
        "        print(f\"Prediction: Deepfake (Confidence: {avg_prediction * 100:.2f}%)\")\n",
        "    else:\n",
        "        print(f\"Prediction: Real (Confidence: {(1 - avg_prediction) * 100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMHlf1lOi0H_",
        "outputId": "f2a77a10-f6e7-440e-ea1d-ab11c3945133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step\n",
            "Prediction: Real (Confidence: 100.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the video file\n",
        "video_path = '/content/00131.mp4'\n",
        "\n",
        "# Extract frames from the video\n",
        "frames = extract_frames_from_video(video_path)\n",
        "\n",
        "# Check if the number of frames is less than the required sequence length\n",
        "sequence_length = 10  # This should match what the 3D CNN model was trained on\n",
        "if len(frames) < sequence_length:\n",
        "    print(f\"Video is too short! Needs at least {sequence_length} frames.\")\n",
        "else:\n",
        "    # Create sequences from the frames\n",
        "    frame_sequences = create_frame_sequences(frames, sequence_length)\n",
        "\n",
        "    # Predict using the 3D CNN model\n",
        "    predictions = model.predict(frame_sequences)\n",
        "\n",
        "    # Average the predictions across all sequences\n",
        "    avg_prediction = np.mean(predictions)\n",
        "\n",
        "    # Output the result\n",
        "    if avg_prediction > 0.5:\n",
        "        print(f\"Prediction: Deepfake (Confidence: {avg_prediction * 100:.2f}%)\")\n",
        "    else:\n",
        "        print(f\"Prediction: Real (Confidence: {(1 - avg_prediction) * 100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYFwKFMkjEd4",
        "outputId": "6d28295c-042d-42a8-8329-027638e63b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step\n",
            "Prediction: Real (Confidence: 55.14%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the pre-trained 2D CNN model\n",
        "model = load_model('model.h5')  # Assuming you saved your 2D CNN as 'model.h5'\n",
        "\n",
        "# Define a function to extract frames from the video\n",
        "def extract_frames_from_video(video_path, target_size=(128, 128)):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Resize the frame to match model input size\n",
        "        resized_frame = cv2.resize(frame, target_size)\n",
        "        normalized_frame = resized_frame.astype('float32') / 255.0  # Normalize to [0,1]\n",
        "\n",
        "        frames.append(normalized_frame)\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "# Path to the video file\n",
        "video_path = '/content/00131.mp4'\n",
        "\n",
        "# Extract frames from the video\n",
        "frames = extract_frames_from_video(video_path)\n",
        "\n",
        "# Predict each frame using the 2D CNN model\n",
        "predictions = model.predict(frames)\n",
        "\n",
        "# Average the predictions across all frames\n",
        "avg_prediction = np.mean(predictions)\n",
        "\n",
        "# Output the result\n",
        "if avg_prediction > 0.5:\n",
        "    print(f\"Prediction: Deepfake \")\n",
        "else:\n",
        "    print(f\"Prediction: Real \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvOGLylljZq0",
        "outputId": "da2a6d01-44b8-4858-b453-9a56f2b15b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Prediction: Real \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the video file\n",
        "video_path = '/content/00519.mp4'\n",
        "\n",
        "# Extract frames from the video\n",
        "frames = extract_frames_from_video(video_path)\n",
        "\n",
        "# Predict each frame using the 2D CNN model\n",
        "predictions = model.predict(frames)\n",
        "\n",
        "# Average the predictions across all frames\n",
        "avg_prediction = np.mean(predictions)\n",
        "\n",
        "# Output the result\n",
        "if avg_prediction > 0.5:\n",
        "    print(f\"Prediction: Deepfake \")\n",
        "else:\n",
        "    print(f\"Prediction: Real \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNMn9pWKjfTY",
        "outputId": "55d7414b-517a-4b7c-f44a-bff260df71e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step\n",
            "Prediction: Deepfake \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "video_path = '/content/02480.mp4'\n",
        "\n",
        "# Extract frames from the video\n",
        "frames = extract_frames_from_video(video_path)\n",
        "\n",
        "# Predict each frame using the 2D CNN model\n",
        "predictions = model.predict(frames)\n",
        "\n",
        "# Average the predictions across all frames\n",
        "avg_prediction = np.mean(predictions)\n",
        "\n",
        "# Output the result\n",
        "if avg_prediction > 0.5:\n",
        "    print(f\"Prediction: Deepfake \")\n",
        "else:\n",
        "    print(f\"Prediction: Real \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxx8uZuHlMXq",
        "outputId": "c136a889-1194-40ed-f313-dcfe1d66fb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Prediction: Deepfake \n"
          ]
        }
      ]
    }
  ]
}